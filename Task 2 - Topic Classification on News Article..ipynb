{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Topic Classification on News Article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Analysis the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # here we are importing pandas liberary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv('BBC News Train.csv')# import the dataset of BBC news \n",
    "dataset.shape # check the dimensional of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head() # check head of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique=dataset.ArticleId.unique() # here we are checking the data in ArticleId  column is uniuqe or not.if it is unique then drop this column.\n",
    "unique.shape #this ArticleId column data is unique so droping this column. beacuse it wont be impact of our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>howard  truanted to play snooker  conservative...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wales silent on grand slam talk rhys williams ...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>french honour for director parker british film...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>car giant hit by mercedes slump a slump in pro...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fockers fuel festive film chart comedy meet th...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>blair rejects iraq advice calls tony blair has...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>housewives lift channel 4 ratings the debut of...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>uk coal plunges into deeper loss shares in uk ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bp surges ahead on high oil price oil giant bp...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ireland 21-19 argentina an injury-time dropped...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wenger signs new deal arsenal manager arsene w...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>u2 s desire to be number one u2  who have won ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hantuchova in dubai last eight daniela hantuch...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>melzer shocks agassi in san jose second seed a...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>moving mobile improves golf swing a mobile pho...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hewitt overcomes wobble in sydney lleyton hewi...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>carry on star patsy rowlands dies actress pats...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>serena becomes world number two serena william...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ferguson urges henry punishment sir alex fergu...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bt boosts its broadband packages british telec...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>china had role in yukos split-up china lent ru...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>peer-to-peer nets  here to stay  peer-to-peer ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>henman to face saulnier test british number on...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>uk will stand firm on eu rebate  britain s £3b...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>iran budget seeks state sell-offs iran s presi...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>music man to the oscars bill conti s job of mu...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>speech takes on search engines a scottish firm...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>da vinci code is  lousy history  the plot of a...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>abbas  will not tolerate  attacks palestinian ...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>broadband set to revolutionise tv bt is starti...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>warnings about junk mail deluge the amount of ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>house prices drop as sales slow house prices f...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>charvis set to lose fitness bid flanker colin ...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>preview: ireland v england (sun) lansdowne roa...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>warnings on woeful wi-fi security companies ar...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>golden economic period  to end ten years of  g...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>ferrero eyes return to top form former world n...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>kelly trails new discipline power teachers cou...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>dallaglio eyeing lions tour place former engla...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>indy buys into india paper irish publishing gr...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>budget to set scene for election gordon brown ...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>bollywood draws global stars british actress a...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>web logs aid disaster recovery some of the mos...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>visa row mandarin made sir john the top civil ...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>high fuel costs hit us airlines two of the lar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>qantas sees profits fly to record australian a...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>liverpool pledge to keep gerrard liverpool chi...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>file-swappers ready new network legal attacks ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>beastie boys win sampling battle us rappers be...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>hyundai to build new india plant south korea s...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>double eviction from big brother model caprice...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>dj double act revamp chart show dj duo jk and ...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>weak dollar hits reuters revenues at media gro...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>apple ipod family expands market apple has exp...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>santy worm makes unwelcome visit thousands of ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text       Category\n",
       "0     worldcom ex-boss launches defence lawyers defe...       business\n",
       "1     german business confidence slides german busin...       business\n",
       "2     bbc poll indicates economic gloom citizens in ...       business\n",
       "3     lifestyle  governs mobile choice  faster  bett...           tech\n",
       "4     enron bosses in $168m payout eighteen former e...       business\n",
       "5     howard  truanted to play snooker  conservative...       politics\n",
       "6     wales silent on grand slam talk rhys williams ...          sport\n",
       "7     french honour for director parker british film...  entertainment\n",
       "8     car giant hit by mercedes slump a slump in pro...       business\n",
       "9     fockers fuel festive film chart comedy meet th...  entertainment\n",
       "10    blair rejects iraq advice calls tony blair has...       politics\n",
       "11    housewives lift channel 4 ratings the debut of...  entertainment\n",
       "12    uk coal plunges into deeper loss shares in uk ...       business\n",
       "13    bp surges ahead on high oil price oil giant bp...       business\n",
       "14    ireland 21-19 argentina an injury-time dropped...          sport\n",
       "15    wenger signs new deal arsenal manager arsene w...          sport\n",
       "16    u2 s desire to be number one u2  who have won ...  entertainment\n",
       "17    hantuchova in dubai last eight daniela hantuch...          sport\n",
       "18    melzer shocks agassi in san jose second seed a...          sport\n",
       "19    moving mobile improves golf swing a mobile pho...           tech\n",
       "20    hewitt overcomes wobble in sydney lleyton hewi...          sport\n",
       "21    carry on star patsy rowlands dies actress pats...  entertainment\n",
       "22    serena becomes world number two serena william...          sport\n",
       "23    ferguson urges henry punishment sir alex fergu...          sport\n",
       "24    bt boosts its broadband packages british telec...           tech\n",
       "25    china had role in yukos split-up china lent ru...       business\n",
       "26    peer-to-peer nets  here to stay  peer-to-peer ...           tech\n",
       "27    henman to face saulnier test british number on...          sport\n",
       "28    uk will stand firm on eu rebate  britain s £3b...       politics\n",
       "29    iran budget seeks state sell-offs iran s presi...       business\n",
       "...                                                 ...            ...\n",
       "1460  music man to the oscars bill conti s job of mu...  entertainment\n",
       "1461  speech takes on search engines a scottish firm...           tech\n",
       "1462  da vinci code is  lousy history  the plot of a...  entertainment\n",
       "1463  abbas  will not tolerate  attacks palestinian ...       politics\n",
       "1464  broadband set to revolutionise tv bt is starti...           tech\n",
       "1465  warnings about junk mail deluge the amount of ...           tech\n",
       "1466  house prices drop as sales slow house prices f...       business\n",
       "1467  charvis set to lose fitness bid flanker colin ...          sport\n",
       "1468  preview: ireland v england (sun) lansdowne roa...          sport\n",
       "1469  warnings on woeful wi-fi security companies ar...           tech\n",
       "1470  golden economic period  to end ten years of  g...       business\n",
       "1471  ferrero eyes return to top form former world n...          sport\n",
       "1472  kelly trails new discipline power teachers cou...       politics\n",
       "1473  dallaglio eyeing lions tour place former engla...          sport\n",
       "1474  indy buys into india paper irish publishing gr...       business\n",
       "1475  budget to set scene for election gordon brown ...       politics\n",
       "1476  bollywood draws global stars british actress a...  entertainment\n",
       "1477  web logs aid disaster recovery some of the mos...           tech\n",
       "1478  visa row mandarin made sir john the top civil ...       politics\n",
       "1479  high fuel costs hit us airlines two of the lar...       business\n",
       "1480  qantas sees profits fly to record australian a...       business\n",
       "1481  liverpool pledge to keep gerrard liverpool chi...          sport\n",
       "1482  file-swappers ready new network legal attacks ...           tech\n",
       "1483  beastie boys win sampling battle us rappers be...  entertainment\n",
       "1484  hyundai to build new india plant south korea s...       business\n",
       "1485  double eviction from big brother model caprice...  entertainment\n",
       "1486  dj double act revamp chart show dj duo jk and ...  entertainment\n",
       "1487  weak dollar hits reuters revenues at media gro...       business\n",
       "1488  apple ipod family expands market apple has exp...           tech\n",
       "1489  santy worm makes unwelcome visit thousands of ...           tech\n",
       "\n",
       "[1490 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop(['ArticleId'],axis=1) # here drop ArticleId column. (axis=1 mean column.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Check Null values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArticleId    0\n",
       "Text         0\n",
       "Category     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check Nulll values\n",
    "dataset.isnull().sum() # no null values in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.preprocessing of the text\n",
    "## for preprocessing we will use tlnk liberary for NLP task and preprocessing of text data.\n",
    "### we will remove stopwords from text .and perform Lemmatizer on each and every words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing # import this liberary for perform label encoding technique on categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()  # initiallize \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Category']= label_encoder.fit_transform(dataset['Category'])  # perform label encoding technique on dependent feature , convert categorical variable into some labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...         0\n",
       "1        154  german business confidence slides german busin...         0\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...         0\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...         4\n",
       "4        917  enron bosses in $168m payout eighteen former e...         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head() # here check out the categorical dependent variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490\n"
     ]
    }
   ],
   "source": [
    "data_sen=dataset['Text'] # its our independent feature and we will do preprocessing on it.so we are retriveing only Text feature from dataset. \n",
    "print(len(data_sen)) # length is 1490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_variable=dataset['Category'] # its our dependent feature. we will use further ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time of preprocessing of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk     #nltk liberary use for preprocessing of text and for NLP task \n",
    "import re       # its for expression \n",
    "from nltk.corpus import stopwords #its removes stopwords like is are we etc from sentences(text).\n",
    "from nltk.stem import WordNetLemmatizer # its liberary for Lemmatization (its liberary to convert meaningless words into some meaningfull.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_preprocessing_of_text=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lemmatizer = WordNetLemmatizer() # intilize the WordNetLemmatizer and create object Lemmatizerz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the main logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0, len(data_sen)): # this loop go till len of the data_Sen ( 0 to 1489)\n",
    "    rev = re.sub('[^a-zA-Z]', ' ', data_sen[i]) # its remove special characters from text. data_sen[i] mean it will take paragraph of ith location and move one by one to the end.\n",
    "    rev = rev.lower() # convert all words into lower case.\n",
    "    rev = rev.split() #perform Tokenizer\n",
    "    \n",
    "    rev = [Lemmatizer.lemmatize(word) for word in rev if not word in stopwords.words('english')] # this statement remove stopwords from paragraphs and perform Lemmatiizations.for this we used list comprehension \n",
    "    rev = ' '.join(rev) # here after perform stopwords and lemmatizations again we are perforing join on which we did spilte .\n",
    "    after_preprocessing_of_text.append(rev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worldcom ex bos launch defence lawyer defending former worldcom chief bernie ebbers battery fraud charge called company whistleblower first witness cynthia cooper worldcom ex head internal accounting alerted director irregular accounting practice u telecom giant warning led collapse firm following discovery bn bn accounting fraud mr ebbers pleaded guilty charge fraud conspiracy prosecution lawyer argued mr ebbers orchestrated series accounting trick worldcom ordering employee hide expense inflate revenue meet wall street earnings estimate m cooper run consulting business told jury new york wednesday external auditor arthur andersen approved worldcom accounting early said andersen given green light procedure practice used worldcom mr ebber lawyer said unaware fraud arguing auditor alert problem m cooper also said shareholder meeting mr ebbers often passed technical question company finance chief giving brief answer prosecution star witness former worldcom financial chief scott sullivan said mr ebbers ordered accounting adjustment firm telling hit book however m cooper said mr sullivan mentioned anything uncomfortable worldcom accounting audit committee meeting mr ebbers could face jail sentence year convicted charge facing worldcom emerged bankruptcy protection known mci last week mci agreed buyout verizon communication deal valued bn'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_preprocessing_of_text[0] # its 1st index text and  here you can check all stopwords have  been removed. and most of the words is  meaningfull."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. after preprocessing we are going to  perform one hot representation technique.[TF-IDF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer  # this liberary use for perform TF-IDF\n",
    "TF_IDF_tech = TfidfVectorizer() #initialize here \n",
    " \n",
    "X = TF_IDF_tech.fit_transform(after_preprocessing_of_text).toarray() # convert words into vectors with the help of TF-IDF technique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 20830)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # after perform TF-IDF its  our new dataframe structure. total no of 20830 independemt features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 2, 3, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_variable.unique() # here we are checking total categorizes of dependent feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model creation and development phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix # import confusion_matrix for check the accuarcy of classfications models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # we are going to use logistics  regression for multiclasses problem .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ourmodel = LogisticRegression(solver = 'lbfgs') # intialize the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # import libeary for test train splite\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, output_variable, test_size=0.3, random_state=1) # here we are spliting the data into train and test\n",
    "# 30% for testing and 70% for training using random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Puneet Singh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ourmodel.fit(X_train,y_train) # fit independent and dependent features into model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. check the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 0, 0, 1, 0, 0, 2, 2, 2, 3, 1, 3, 4, 1, 3, 1, 4, 1, 3, 3, 3,\n",
       "       4, 2, 2, 4, 2, 0, 1, 2, 0, 4, 1, 4, 4, 3, 0, 3, 3, 3, 0, 1, 2, 1,\n",
       "       1, 0, 3, 4, 0, 0, 2, 4, 1, 2, 4, 0, 2, 1, 0, 4, 4, 3, 1, 3, 0, 0,\n",
       "       4, 3, 3, 2, 2, 2, 0, 4, 4, 2, 3, 0, 1, 1, 3, 3, 2, 2, 4, 2, 3, 4,\n",
       "       1, 0, 3, 0, 4, 1, 3, 3, 2, 3, 0, 0, 0, 3, 2, 4, 0, 1, 3, 3, 1, 0,\n",
       "       4, 4, 1, 3, 2, 4, 4, 4, 2, 1, 3, 1, 3, 4, 4, 1, 2, 4, 0, 3, 3, 1,\n",
       "       4, 1, 2, 3, 4, 1, 2, 2, 0, 1, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 2, 3,\n",
       "       0, 2, 4, 3, 3, 3, 4, 0, 1, 3, 0, 4, 1, 1, 4, 2, 3, 0, 2, 4, 1, 3,\n",
       "       3, 3, 3, 3, 1, 0, 0, 3, 2, 2, 1, 3, 2, 0, 3, 1, 4, 3, 4, 3, 2, 3,\n",
       "       0, 4, 1, 2, 1, 3, 0, 2, 2, 4, 1, 4, 2, 3, 0, 0, 2, 2, 4, 3, 0, 3,\n",
       "       0, 0, 3, 0, 3, 4, 0, 0, 0, 0, 1, 3, 4, 0, 4, 0, 1, 1, 0, 1, 2, 2,\n",
       "       3, 0, 3, 4, 3, 4, 0, 2, 4, 0, 1, 3, 1, 1, 0, 1, 0, 1, 1, 3, 0, 0,\n",
       "       1, 4, 0, 3, 4, 3, 4, 0, 1, 0, 2, 0, 1, 3, 0, 0, 0, 0, 2, 4, 0, 2,\n",
       "       4, 4, 4, 4, 4, 4, 3, 2, 3, 0, 0, 3, 4, 2, 2, 2, 3, 3, 2, 3, 4, 1,\n",
       "       0, 2, 3, 4, 2, 0, 0, 0, 0, 0, 0, 4, 1, 0, 2, 1, 1, 0, 2, 4, 4, 0,\n",
       "       2, 3, 1, 1, 4, 4, 2, 0, 3, 4, 2, 1, 0, 3, 4, 0, 2, 2, 3, 3, 0, 2,\n",
       "       3, 4, 1, 3, 3, 4, 2, 1, 2, 4, 1, 3, 2, 1, 4, 1, 2, 0, 2, 2, 4, 3,\n",
       "       4, 3, 2, 4, 3, 1, 3, 1, 0, 1, 3, 0, 4, 1, 4, 3, 2, 0, 4, 0, 3, 0,\n",
       "       3, 2, 3, 0, 3, 3, 4, 3, 3, 1, 1, 2, 1, 1, 2, 1, 0, 3, 0, 0, 1, 3,\n",
       "       0, 0, 3, 2, 4, 2, 2, 4, 1, 3, 4, 0, 1, 3, 3, 3, 1, 4, 3, 4, 1, 0,\n",
       "       4, 3, 4, 2, 2, 4, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ourmodel.predict(X_test) # here is prediction\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. why my model is best ?\n",
    "## for this we are going to use cross-validation technique (K fold cross validation technique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Puneet Singh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Puneet Singh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Puneet Singh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Puneet Singh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Puneet Singh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Puneet Singh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Puneet Singh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Puneet Singh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Puneet Singh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Puneet Singh\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score # here we importing cross val score . to calculate our model score \n",
    "score=cross_val_score(ourmodel,X,output_variable,cv=10) #cv=10 mean divied dataset into train and test 10 times and give to the model and model will predict output for 10 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " my model is giving min accuracy is 93% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9337748344370861"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.min() # here we find out the mean of all the accuracy of my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " my model is giving max accuracy is 97% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9798657718120806"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Average accuray is 96 % "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9658745659173746"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my accuracy looking good. if  my mode does not give accuracy well then i will use hyperparameter optimization tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
